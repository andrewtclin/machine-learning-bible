{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "\n",
    "<img src='../../resources/deep_learning/dl.png' />\n",
    "\n",
    "* Mimic how the human brain operates\n",
    "    * Input Values (Input Layer)\n",
    "    * Hidden Layer\n",
    "    * Output Value (Output Layer)\n",
    "<img src='../../resources/deep_learning/ann/dl1.png' />\n",
    "<img src='../../resources/deep_learning/ann/dl2.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Networks (ANN)\n",
    "\n",
    "* The Neuron\n",
    "* The Activation Function\n",
    "* How do Neural Networks work?\n",
    "* How do Neural Networks learn?\n",
    "* Gradient Descent\n",
    "* Stochastic Gradient Descent\n",
    "* Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='../../resources/deep_learning/ann/ann1.png' />\n",
    "\n",
    "* Input layer contains **independent variable**\n",
    "    * Make sure to standardize them\n",
    "        * Mean of 0 & variance of 1\n",
    "    * Sometimes normalize them\n",
    "    \n",
    "<img src='../../resources/deep_learning/ann/ann2.png' />\n",
    "\n",
    "* Output values can be:\n",
    "    * Continuous (price)\n",
    "    * Binary (Yes/No)\n",
    "    * Categorical - **Results in `mutiple` output values**\n",
    "    \n",
    "<img src='../../resources/deep_learning/ann/ann3.png' />\n",
    "\n",
    "* Synapses - **Weights**\n",
    "    * Weights: How Neural Networks Learn\n",
    "        * Assigns what signals are important & what not\n",
    "        * The things that get `adjusted` for the training\n",
    "            * where gradient descent & backward propagation comes into play.\n",
    "            \n",
    "<img src='../../resources/deep_learning/ann/ann4.png' />\n",
    "\n",
    "* What happens inside the `neuron`?\n",
    "    1. All of the input values get added up\n",
    "    2. Then, applies `activation` function.\n",
    "\n",
    "<img src='../../resources/deep_learning/ann/ann5.png' />\n",
    "<img src='../../resources/deep_learning/ann/ann6.png' />\n",
    "\n",
    "* Then, the neuron passes on the signal.\n",
    "\n",
    "<img src='../../resources/deep_learning/ann/ann7.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function\n",
    "\n",
    "* The signal that is being passed on.\n",
    "<img src='../../resources/deep_learning/ann/ann8.png' />\n",
    "\n",
    "\n",
    "* 4 predominant types of activation functions:\n",
    "1. Threshold Function (Yes/No type of function)\n",
    "    * x-axis: weighted sum\n",
    "    * y-axis: values 0-1\n",
    "    * Threshold function passes:\n",
    "        * x >= 0, then 1\n",
    "        * x < 0,  then 0\n",
    "<img src='../../resources/deep_learning/ann/ann9.png' />    \n",
    "\n",
    "2. Sigmoid Function\n",
    "   * 1 / (1 + e^-x)\n",
    "   * x-axis: weighted sum\n",
    "   * It is smooth & gradual progression\n",
    "       * Very useful in the output layer\n",
    "       * Especially for predicting probabilities.\n",
    "    \n",
    "<img src='../../resources/deep_learning/ann/ann10.png' /> \n",
    "\n",
    "3. Rectifier Function\n",
    "   * One of the most popular function for ANN\n",
    "   * Goes all the way to 0 at 0, and increases from there.\n",
    "\n",
    "<img src='../../resources/deep_learning/ann/ann11.png' /> \n",
    "\n",
    "4. Hyperbolic Tangent (tanh)\n",
    "   * Similar to sigmoid, but goes below 0\n",
    "       * Goes from -1 to 0, then 0 to 1\n",
    "\n",
    "<img src='../../resources/deep_learning/ann/ann12.png' /> \n",
    "\n",
    "\n",
    "\n",
    "* Deciding which function to use for Dependent Variable 0 or 1\n",
    "    * Sigmoid: Tells the probability of y being 1\n",
    "    \n",
    "<img src='../../resources/deep_learning/ann/ann13.png' /> \n",
    "\n",
    "* A function being passed in at `Hidden Layer`, then a function being passed in at `Output layer`, then yields an output.\n",
    "\n",
    "<img src='../../resources/deep_learning/ann/ann14.png' /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do Neural Networks work?\n",
    "\n",
    "* Pretend a NN is **trained**, using housing price as example.\n",
    "    * Input Layer: X1(Area), X2(Bedrooms), X3(Distance to city), X4(Age)\n",
    "    * Output Layer: Price that we are predicting\n",
    "        * Input Layer will be weighted up by synapses\n",
    "        * Output Layer will be calculated\n",
    "            * Price = w1x1 + w2x2 + w3x3 + w4x4 (Weighted sum of all of the inputs)\n",
    "            \n",
    "        <img src='../../resources/deep_learning/ann/ann15.png' /> \n",
    "        \n",
    "        * Hidden Layer gives extra power\n",
    "            * All inputs passed with weights, but **not** all inputs are value - some are 0 some are not 0\n",
    "            * This neuron might be looking for a specific relevant thing, a property not so far from the city & the size.\n",
    "            * The activation function will fire up only when certain criteria is met.\n",
    "            \n",
    "        <img src='../../resources/deep_learning/ann/ann16.png' /> \n",
    "        \n",
    "        * A neuron might also pick up only 1 variable\n",
    "            * If a property > 100y, deemd as historic & fired up\n",
    "            * Good example of **rectifier function**\n",
    "            \n",
    "        <img src='../../resources/deep_learning/ann/ann17.png' /> \n",
    "        \n",
    "        * Together, they have strong power to predict the price\n",
    "        \n",
    "        <img src='../../resources/deep_learning/ann/ann18.png' /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do Neural Network learn?\n",
    "\n",
    "* Avoid putting in the rule, and let the program learn by itself.\n",
    "\n",
    "* y^ is the output value; y is the actual value\n",
    "\n",
    "<img src='../../resources/deep_learning/ann/ann19.png' /> \n",
    "\n",
    "* Let's say inputs applied, then activation function applied, and an output y^ is given. We compare it to actual value y.\n",
    "    1. Calculate Cost Function: C = 1/2(y^-y)^2\n",
    "        * Tells the error in the prediction.\n",
    "        * The goal is to `minimize` the cost function.\n",
    "    2. We then feed the info on cost function back to the neural network.\n",
    "    3. Goes back to the weights, and the weights get updated.\n",
    "        * The only thing we have in control is the weights (W1 - Wm)\n",
    "    4. Repeat & adjust the weights, changes y^\n",
    "        \n",
    "    * **Note:** We are only dealing with dataset of **one row**.\n",
    "        <img src='../../resources/deep_learning/ann/ann20.png' /> \n",
    "        \n",
    "* Let's see **multiple rows**\n",
    "    * 1 epoch is when we go through the whole dataset & train the neural network on all of these rows.\n",
    "    * After getting **all of the values & compare with actual values**, we can calculate the **cost function** of all: **sum of 1/2(y^ - y)^2**\n",
    "    * We then go back and update all.\n",
    "    * **Note:** All of these are 1 neural network. All of the rows **Share the weights**.\n",
    "\n",
    "\n",
    "* The goal is to minimize the cost function - find optimal weights\n",
    "    * This is **Backpropagation**\n",
    "<img src='../../resources/deep_learning/ann/ann21.png' /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent\n",
    "\n",
    "* In order for a Neural Network to learn, we use **backpropagation**, and adjust the weights accordingly.\n",
    "\n",
    "* How the weight is adjusted/minimize the cost function:\n",
    "    * One of the way is the: Brute Force method\n",
    "    * <img src='../../resources/deep_learning/ann/ann22.png' /> \n",
    "\n",
    "* **But**, if we increase the number of weights, we will encounter **Curse of Dimensionality**\n",
    "    * Before a neural network is trained:\n",
    "    * <img src='../../resources/deep_learning/ann/ann23.png' /> \n",
    "    \n",
    "    * It takes **way too long, unrealistic**.\n",
    "    \n",
    "    * <img src='../../resources/deep_learning/ann/ann24.png' /> \n",
    "    \n",
    "    \n",
    "* Therefore, we use **gradient descent**\n",
    "    *  We first find a point where the cost function starts\n",
    "        * We then look at the **angle** of cost function (gradient).\n",
    "        * If **slope = -ve**, it is **going downhill**, goes right.\n",
    "        * If **slope = +ve**, it is **going uphill**, goes left.\n",
    "            * Repeat & find the **best weights** (Like ball rolling)\n",
    "            * Basically, see which way it is going downwards.\n",
    "            \n",
    "    * <img src='../../resources/deep_learning/ann/ann25.png' /> \n",
    "    \n",
    "    * Gradient descent in **two-dimensional** space.\n",
    "        * Descending into the **minimum** of the cost function.\n",
    "    \n",
    "    * <img src='../../resources/deep_learning/ann/ann26.png' /> \n",
    "    \n",
    "    * Gradient descent in **three-dimensional** space.\n",
    "    * <img src='../../resources/deep_learning/ann/ann27.png' /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "* For a regular gradient descent, we require the Cost Function is `convex`.\n",
    "\n",
    "* What if it looks:\n",
    "    * We might found a wrong one for non-convex cost function.\n",
    "    * <img src='../../resources/deep_learning/ann/ann28.png' /> \n",
    "    \n",
    "    * We need Stochastic Gradient Descent\n",
    "        * Does not require the cost function to be convex.\n",
    "        * We take the rows one by one, unlike the regular gradient descent, known as batch gradient descent.\n",
    "        * Take the row one by one & adjust the weights. Adjust the weights after **every single row**.\n",
    "        * <img src='../../resources/deep_learning/ann/ann29.png' /> \n",
    "        \n",
    "    * Stochastic Gradient Descent:\n",
    "        * Helps avoid local minimum instead of `global minimum`.\n",
    "        * Much higher fluctuation - one iteration/one row at a time.\n",
    "        * It is **faster** as it does not have to load up data in the memory by doing one by one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation\n",
    "\n",
    "* Forward Propagation\n",
    "    * Information entered into the input layer & propagated forward.\n",
    "    * Get output value y^ & compare to the actual value y.\n",
    "    * Then, calculated the error.\n",
    "    \n",
    "* Backpropagation\n",
    "    * The error is then backpropagated, allows us to adjust the weights to train the network.\n",
    "    * Advanced algorithm which allows to adjust all of the weights simultaneously. \n",
    "    * During the process, because of the way the algorithm is structured, we are able to adjust all of the weights at the same time.\n",
    "        * Know which part of the error each of the weights in the network is responsible for.\n",
    "\n",
    "\n",
    "**Steps: Training the ANN with Stochastic Gradient Descent**\n",
    "\n",
    "1. Randomly initialise the weights to small numbers close to 0, but not 0.\n",
    "\n",
    "2. Input the first observation of the dataset in the input layer, each feature in one input node.\n",
    "\n",
    "3. Forward Propagation: from left to right, the neurons are activated in a way that the impact of each neuron's activation is limited by the weights. Propagate the activations until getting the predicted result y^. (The weights determine how important each neuron activation is)\n",
    "\n",
    "4. Compare the predicted result to the actual result. Measure the generated error.\n",
    "\n",
    "5. Back Propagation: from right to left, the error is back propagatted. Update the weights accoridng to how much they are responsible for the error. The learning rate decides how much we update the weights.\n",
    "\n",
    "6. Repeat Steps 1 - 5 & update the weights after each observation (Reinforcement Learning/Stochastic GD). Or Repeat Steps 1 - 5 but update the weights only after a batch of observations (Batch Learning/Batch GD/ Mini Batch GD).\n",
    "\n",
    "7. When whole training set passed through the ANN, that makes an epcoh. Redo more epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.11.0'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/churn_modelling.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, 3:-1]\n",
    "y = df['Exited'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France  Female   42       2       0.00              1   \n",
       "1          608     Spain  Female   41       1   83807.86              1   \n",
       "2          502    France  Female   42       8  159660.80              3   \n",
       "3          699    France  Female   39       1       0.00              2   \n",
       "4          850     Spain  Female   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[98], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder() # Encoding Label Values\n",
    "X['Gender'] = le.fit_transform(X['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0          619    France       0   42       2       0.00              1   \n",
       "1          608     Spain       0   41       1   83807.86              1   \n",
       "2          502    France       0   42       8  159660.80              3   \n",
       "3          699    France       0   39       1       0.00              2   \n",
       "4          850     Spain       0   43       2  125510.82              1   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0          1               1        101348.88  \n",
       "1          0               1        112542.58  \n",
       "2          1               0        113931.57  \n",
       "3          0               0         93826.63  \n",
       "4          1               1         79084.10  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Use OneHotEncoder as there is no relationship between them, so couldn't just assign 0, 1, 2\n",
    "\n",
    "categorical_features = ['Geography']\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[('encoder', OneHotEncoder(), categorical_features)],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.0000000e+00\n",
      "  1.0000000e+00 1.0134888e+05]\n",
      " [0.0000000e+00 0.0000000e+00 1.0000000e+00 ... 0.0000000e+00\n",
      "  1.0000000e+00 1.1254258e+05]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.0000000e+00\n",
      "  0.0000000e+00 1.1393157e+05]\n",
      " ...\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 0.0000000e+00\n",
      "  1.0000000e+00 4.2085580e+04]\n",
      " [0.0000000e+00 1.0000000e+00 0.0000000e+00 ... 1.0000000e+00\n",
      "  0.0000000e+00 9.2888520e+04]\n",
      " [1.0000000e+00 0.0000000e+00 0.0000000e+00 ... 1.0000000e+00\n",
      "  0.0000000e+00 3.8190780e+04]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Scaling**\n",
    "\n",
    "* Compulsory for Deep Learning\n",
    "    * Apply to **ALL** the features regardless of the value, even if 0 & 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding input layer & first hidden layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected layer is via 'Dense' class\n",
    "# neurons in hidden layer = 6\n",
    "# experiment with hyperparameters to know # of neurons\n",
    "# activation function = reLU\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding the second hidden layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adding the output layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we were doing classification with non-binary, like ABC, we need it to be units=3 as no correlation between ABC\n",
    "# For non-binary classification, activaton='softmax'\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid')) # Sigmoid gives the outcome of binary & probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compiling ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best optimizer is the one that can perform Stochastic Gradient Descent\n",
    "# For non-binary classification, loss='categorical_crossentropy'\n",
    "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training ANN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "250/250 [==============================] - 1s 1ms/step - loss: 0.5489 - accuracy: 0.7632\n",
      "Epoch 2/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7964\n",
      "Epoch 3/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4485 - accuracy: 0.7972\n",
      "Epoch 4/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4294 - accuracy: 0.8059\n",
      "Epoch 5/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.4130 - accuracy: 0.8230\n",
      "Epoch 6/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3992 - accuracy: 0.8311\n",
      "Epoch 7/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3894 - accuracy: 0.8388\n",
      "Epoch 8/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3813 - accuracy: 0.8425\n",
      "Epoch 9/100\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.3744 - accuracy: 0.8462\n",
      "Epoch 10/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3675 - accuracy: 0.8495\n",
      "Epoch 11/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3617 - accuracy: 0.8505\n",
      "Epoch 12/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3560 - accuracy: 0.8539\n",
      "Epoch 13/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3525 - accuracy: 0.8556\n",
      "Epoch 14/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3493 - accuracy: 0.8569\n",
      "Epoch 15/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3465 - accuracy: 0.8594\n",
      "Epoch 16/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3447 - accuracy: 0.8597\n",
      "Epoch 17/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3430 - accuracy: 0.8584\n",
      "Epoch 18/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3417 - accuracy: 0.8601\n",
      "Epoch 19/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3405 - accuracy: 0.8609\n",
      "Epoch 20/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8605\n",
      "Epoch 21/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3393 - accuracy: 0.8608\n",
      "Epoch 22/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8630\n",
      "Epoch 23/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8619\n",
      "Epoch 24/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.8612\n",
      "Epoch 25/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8605\n",
      "Epoch 26/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8625\n",
      "Epoch 27/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3371 - accuracy: 0.8612\n",
      "Epoch 28/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3367 - accuracy: 0.8616\n",
      "Epoch 29/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8627\n",
      "Epoch 30/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8631\n",
      "Epoch 31/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3362 - accuracy: 0.8625\n",
      "Epoch 32/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3360 - accuracy: 0.8624\n",
      "Epoch 33/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8625\n",
      "Epoch 34/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3359 - accuracy: 0.8620\n",
      "Epoch 35/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8639\n",
      "Epoch 36/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3358 - accuracy: 0.8633\n",
      "Epoch 37/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3356 - accuracy: 0.8621\n",
      "Epoch 38/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3354 - accuracy: 0.8634\n",
      "Epoch 39/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3351 - accuracy: 0.8636\n",
      "Epoch 40/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8630\n",
      "Epoch 41/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3353 - accuracy: 0.8626\n",
      "Epoch 42/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3355 - accuracy: 0.8651\n",
      "Epoch 43/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8630\n",
      "Epoch 44/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8640\n",
      "Epoch 45/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3350 - accuracy: 0.8636\n",
      "Epoch 46/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3349 - accuracy: 0.8633\n",
      "Epoch 47/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3348 - accuracy: 0.8634\n",
      "Epoch 48/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8631\n",
      "Epoch 49/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8646\n",
      "Epoch 50/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8651\n",
      "Epoch 51/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8634\n",
      "Epoch 52/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8648\n",
      "Epoch 53/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8630\n",
      "Epoch 54/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3346 - accuracy: 0.8650\n",
      "Epoch 55/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8633\n",
      "Epoch 56/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.8639\n",
      "Epoch 57/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8655\n",
      "Epoch 58/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3345 - accuracy: 0.8643\n",
      "Epoch 59/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8651\n",
      "Epoch 60/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8648\n",
      "Epoch 61/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8643\n",
      "Epoch 62/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8651\n",
      "Epoch 63/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3343 - accuracy: 0.8637\n",
      "Epoch 64/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8648\n",
      "Epoch 65/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8655\n",
      "Epoch 66/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8635\n",
      "Epoch 67/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8643\n",
      "Epoch 68/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3340 - accuracy: 0.8643\n",
      "Epoch 69/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8649\n",
      "Epoch 70/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3341 - accuracy: 0.8646\n",
      "Epoch 71/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3337 - accuracy: 0.8656\n",
      "Epoch 72/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8637\n",
      "Epoch 73/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3344 - accuracy: 0.8649\n",
      "Epoch 74/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8652\n",
      "Epoch 75/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8652\n",
      "Epoch 76/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3339 - accuracy: 0.8636\n",
      "Epoch 77/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8644\n",
      "Epoch 78/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8648\n",
      "Epoch 79/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3336 - accuracy: 0.8654\n",
      "Epoch 80/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.8654\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3332 - accuracy: 0.8648\n",
      "Epoch 82/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8645\n",
      "Epoch 83/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8665\n",
      "Epoch 84/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3335 - accuracy: 0.8650\n",
      "Epoch 85/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3334 - accuracy: 0.8643\n",
      "Epoch 86/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8646\n",
      "Epoch 87/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8643\n",
      "Epoch 88/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8644\n",
      "Epoch 89/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8649\n",
      "Epoch 90/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8646\n",
      "Epoch 91/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8643\n",
      "Epoch 92/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8640\n",
      "Epoch 93/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3328 - accuracy: 0.8631\n",
      "Epoch 94/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3330 - accuracy: 0.8640\n",
      "Epoch 95/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8640\n",
      "Epoch 96/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8651\n",
      "Epoch 97/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.8650\n",
      "Epoch 98/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8655\n",
      "Epoch 99/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3327 - accuracy: 0.8640\n",
      "Epoch 100/100\n",
      "250/250 [==============================] - 0s 1ms/step - loss: 0.3326 - accuracy: 0.8656\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23787fe4a00>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.fit(X_train, y_train, batch_size=32, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions & Evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting the followings:\n",
    "* Geography = France\n",
    "* Credit Score = 600\n",
    "* Gender = Male\n",
    "* Age = 40\n",
    "* Tenure = 3 years\n",
    "* Balance = \\\\$60,000\n",
    "* Number of Products = 2\n",
    "* Credit Card? = Yes\n",
    "* Active Member? = Yes\n",
    "* Estimated Salary = \\\\$50,000\n",
    "\n",
    "Will the customer leave?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[False]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predicting Test Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_preds = ann.predict(X_test)\n",
    "y_preds = (y_preds > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x2378d6259c0>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.863"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_science_playground]",
   "language": "python",
   "name": "conda-env-data_science_playground-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
